<!DOCTYPE html>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" lang="en-us" xml:lang="en-us" data-mc-search-type="Stem" data-mc-help-system-file-name="Default.xml" data-mc-path-to-help-system="../../" data-mc-target-type="WebHelp2" data-mc-runtime-file-type="Topic" data-mc-preload-images="false" data-mc-in-preview-mode="false" data-mc-toc-path="Use Cases">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta charset="utf-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <link href="../../Skins/Default/Stylesheets/Slideshow.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../Skins/Default/Stylesheets/TextEffects.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../Skins/Default/Stylesheets/Topic.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../Skins/Default/Stylesheets/Components/Styles.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../Skins/Default/Stylesheets/Components/Tablet.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../Skins/Default/Stylesheets/Components/Mobile.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../Skins/Default/Stylesheets/Components/Print.css" rel="stylesheet" type="text/css" data-mc-generated="True" /><title>
			Events
		</title>
        <link href="../Resources/Stylesheets/DocLoc.css" rel="stylesheet" type="text/css" />
        <script src="../../Resources/Scripts/jquery.min.js" type="text/javascript">
        </script>
        <script src="../../Resources/Scripts/purify.min.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../Resources/Scripts/require.min.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../Resources/Scripts/require.config.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../Resources/Scripts/foundation.min.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../Resources/Scripts/plugins.min.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../Resources/Scripts/MadCapAll.js" type="text/javascript" defer="defer">
        </script>
    </head>
    <body>
        <h1><a name="kanchor41"></a>Events</h1>
        <p>Your app can be notified about various events that happen during speech recognition.</p>
        <h2>Session events</h2>
        <p>Your app can be notified whenever recording is started or stopped during a session.</p>
        <p>In your app, include a class that implements the <code>SessionEventListener</code> interface; generally, your speech-enabled activity class. Call the <code>addSessionEventListener()</code> method to register an instance of this class as a listener for session events in the session instance. Make sure that you unregister the listener object before the end of its <a href="../AndroidIntroduction/DANUBE_ACTIVITY_LIFECYCLE_ANDROID.htm">life cycle</a>; call the <code>removeSessionEventListener()</code> method.</p>
        <h3>Example</h3>
        <div><code>public class MySpeechEnabledActivity extends Activity implements SessionEventListener {</code> </div>
        <p class="compact">...</p>
        <p class="compact2"><code>// Activity lifecycle callbacks to register and unregister for session event callbacks properly</code> </p>
        <p class="compact2"><code>@Override</code> </p>
        <p class="compact2"><code>protected void onStart() {</code> </p>
        <p class="compact3"><code>// When the Activity starts (it is already created), register for session event callbacks</code> </p>
        <p class="compact3"><code>Session.getSharedSession().addSessionEventListener(this);</code> </p>
        <p class="compact3"><code>super.onStart();</code> </p>
        <p class="compact2"><code>}</code> </p>
        <p class="compact">&#160;</p>
        <p class="compact2"><code>@Override</code> </p>
        <p class="compact2"><code>protected void onStop() {</code> </p>
        <p class="compact3"><code>// When the Activity stops (before being destroyed), unregister for session event callbacks</code> </p>
        <p class="compact3"><code>Session.getSharedSession().removeSessionEventListener(this);</code> </p>
        <p class="compact3"><code>super.onStop();</code> </p>
        <p class="compact2"><code>}</code> </p>
        <p class="compact">...</p>
        <p class="compact2"><code>// SessionEventListener callback methods</code> </p>
        <p class="compact2"><code>@Override</code> </p>
        <p class="compact2"><code>public void onRecordingStarted() {</code> </p>
        <p class="compact3">...</p>
        <p class="compact2"><code>}</code> </p>
        <p class="compact">&#160;</p>
        <p class="compact2"><code>@Override</code> </p>
        <p class="compact2"><code>public void onRecordingStopped() {</code> </p>
        <p class="compact3">...</p>
        <p class="compact2"><code>}</code> </p>
        <p><code>}</code> </p>
        <h3>Session event listener</h3>
        <p>The <code>SessionEventListener</code> interface contains the following methods:</p>
        <ul>
            <li><code>onRecordingStarted()</code> - called when recording is started.</li>
            <li><code>onRecordingStopped()</code> - called when recording is stopped, either on request or because of an error.</li>
        </ul>
        <p>If your app is notified about session events, you can (among other tasks) implement a record button on your GUI. The appearance of the button reflects the current recording state (for example, a caption/image to indicate recording is started/stopped). The <code>onRecordingStarted()</code> and <code>onRecordingStopped()</code> callbacks notify your app of changes in the recording state, which can be triggered by the user, an error, an idle timeout or any other cause, and enable you to update the appearance of your record button and your internal representation of the recording state.</p>
        <h2>VuiController events</h2>
        <p>Your app can be notified about events related to individual VuiForms. </p>
        <p>To receive VuiController events, your speech-enabled activity must implement the <code>VuiControllerEventListener</code> interface. The VuiController instance automatically detects if this is the case and calls the appropriate callbacks.</p>
        <p>Example: <code>public class MyActivity extends Activity implements VuiControllerEventListener { ...</code></p>
        <p>The <code>VuiControllerEventListener</code> interface contains the following methods:</p>
        <ul>
            <li><code>onProcessingStarted()</code> - called when the user starts their first utterance in any speech-enabled control and the speech recognition process starts.</li>
            <li><code>onProcessingFinished()</code> - called when the last utterance spoken is recognized and the GUI is updated with its results; the speech recognition process is finished, there are no more utterances to be processed.</li>
            <li><code>onProcessingStarted(View view)</code> - called when the user finishes their first utterance in a speech-enabled control and the speech recognition process starts. A reference to the control is supplied as the callback parameter.</li>
            <li><code>onProcessingFinished(View view)</code> - called when the last utterance for a speech-enabled control is recognized and the GUI is updated with the recognition results. A reference to the control is supplied as the callback parameter.</li>
            <li>
                <p><code>onCommandRecognized(String id, String spokenPhrase, String content, HashMap&lt;String, String&gt; placeholderValues)</code> – called when an application command has been recognized. The following information is delivered by the event about the recognized voice command:</p>
            </li>
        </ul>
        <p class="compact2"><code>id</code> - the identifier of the recognized command.</p>
        <p class="compact2"><code>spokenPhrase</code> - the actual phrase that was recognized.</p>
        <p class="compact2"><code>content</code> – deprecated, this parameter is always empty.</p>
        <p class="indent2"><code>placeholderValues</code> - the placeholder identifier and value pairs that are present in the recognized voice command.</p>
        <p class="indent2">For more information, see the <a href="../Concepts/DANUBE_APPLICATION_COMMANDS.htm">application commands concept</a> and the <a href="DANUBE_APPLICATION_COMMANDS_ANDROID.htm">application commands use case</a>.</p>
        <h3>Remarks</h3>
        <ul>
            <li>The processing started/stopped events are always fired in pairs; for every <code>onProcessingStarted()</code> and <code>onProcessingStarted(View view)</code> call, there's a corresponding <code>onProcessingFinished()</code> or <code>onProcessingFinished(View view)</code> call.</li>
            <li>If your app is notified about VuiController events, you can (among other tasks) change the GUI based on whether the speech recognition process is ongoing or has finished, either globally or for a specific control.</li>
            <li>Globally: For example, you want to stop the user navigating away from the current speech-enabled form while speech recognition processing is ongoing (to make sure that no recognition results are lost). In this case, the <code>onProcessingStarted()</code> and the <code>onProcessingStopped()</code> callbacks can be used to disable and enable navigation between forms.</li>
            <li>Specific control: For example, the GUI layout of your app changes based on whether the sound is recorded into a specific control. In this case, wait to change the GUI until all the utterances recorded into that control are completely recognized. By performing the GUI change from the <code>onProcessingFinished(View view)</code> callback, you can make sure that all the relevant recognition results are displayed.</li>
            <li>The <code>onProcessingStarted</code> and <code>onProcessingStopped</code> events (global and text control-specific) are reliable only if recording has already been stopped; the user might start speaking again after the <code>onProcessingStopped</code> event is fired.</li>
            <li>The <code>onProcessingStopped(View view)</code> event is always fired for the control that has the speech focus when the user starts to dictate (for which the <code>onProcessingStarted(View view)</code> event was fired earlier). This guarantees that <code>onProcessingStarted(View view)</code> and <code>onProcessingStopped(View view)</code> events are always fired in pairs for all controls. </li>
            <li>The <code>onProcessingStarted(View view)</code> and <code>onProcessingStopped(View view)</code> callbacks can't track which controls have received recognized results.</li>
        </ul>
        <h3>Scenario</h3>
        <ul>
            <li>There are two controls in the form: Field 1 and Field 2. Field 1 has the speech focus when recording is started.</li>
            <li>The user records three utterances without waiting for the results: <span class="command">this is a test</span>, <span class="command">next field</span> and <span class="command">this is another test</span>. Then recording is stopped.</li>
            <li>When all speech recognition processing is finished, Field 1 contains "This is a test", Field 2 contains "This is another test" and Field 2 has the speech focus.</li>
        </ul>
        <p>How the <code>onProcessingStarted(View view)</code> and <code>onProcessingStopped(View view)</code> events function:</p>
        <ul>
            <li>The user says <span class="command">this is a test</span> when Field 1 has the speech focus: An <code>onProcessingStarted(View view)</code> event is fired for Field 1.</li>
            <li>The user says <span class="command">next field</span> and <span class="command">this is another test</span> when Field 1 has the speech focus: Speech recognition processing is ongoing, therefore no <code>onProcessingStarted(View view)</code> events are fired for these utterances.</li>
            <li>When the recognition results for <span class="command">this is another test</span> are displayed, speech recognition processing is finished, therefore an <code>onProcessingFinished(View view)</code> event is fired for the control which had the speech focus when the user started to say it, in this case Field 1.</li>
            <li>The user didn't start saying anything when the speech focus was in Field 2. No <code>onProcessingStarted(View view)</code> or <code>onProcessingStopped(View view)</code> events are fired for this control even though Field 2 contains the recognition results.</li>
        </ul>
        <p>Conclusion: You can use the <code>onProcessingStarted(View view)</code> and <code>onProcessingStopped(View view)</code> events for this scenario but they aren't reliable in the case of voice navigation or while recording is on.</p>
        <h3>See also</h3>
        <p class="indent2"><a href="DANUBE_GUI_VIEW_ANDROID.htm">Dynamically modified activities</a>
        </p>
    </body>
</html>